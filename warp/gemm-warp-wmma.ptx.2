//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-27506705
// Cuda compilation tools, release 10.2, V10.2.89
// Based on LLVM 3.4svn
//

.version 6.5
.target sm_75
.address_size 64

	// .globl	_Z4GEMMP6__halfS0_PfS1_iii
// _ZZ4GEMMP6__halfS0_PfS1_iiiE5asmem has been demoted
// _ZZ4GEMMP6__halfS0_PfS1_iiiE5bsmem has been demoted
// _ZZ4GEMMP6__halfS0_PfS1_iiiE5csmem has been demoted

.visible .entry _Z4GEMMP6__halfS0_PfS1_iii(
	.param .u64 _Z4GEMMP6__halfS0_PfS1_iii_param_0,
	.param .u64 _Z4GEMMP6__halfS0_PfS1_iii_param_1,
	.param .u64 _Z4GEMMP6__halfS0_PfS1_iii_param_2,
	.param .u64 _Z4GEMMP6__halfS0_PfS1_iii_param_3,
	.param .u32 _Z4GEMMP6__halfS0_PfS1_iii_param_4,
	.param .u32 _Z4GEMMP6__halfS0_PfS1_iii_param_5,
	.param .u32 _Z4GEMMP6__halfS0_PfS1_iii_param_6
)
{
	.reg .pred 	%p<15>;
	.reg .b16 	%rs<3>;
	.reg .f32 	%f<164>;
	.reg .b32 	%r<169>;
	.reg .b64 	%rd<24>;
	// demoted variable
	.shared .align 2 .b8 _ZZ4GEMMP6__halfS0_PfS1_iiiE5asmem[4096];
	// demoted variable
	.shared .align 2 .b8 _ZZ4GEMMP6__halfS0_PfS1_iiiE5bsmem[4096];
	// demoted variable
	.shared .align 4 .b8 _ZZ4GEMMP6__halfS0_PfS1_iiiE5csmem[16384];

	ld.param.u64 	%rd3, [_Z4GEMMP6__halfS0_PfS1_iii_param_0];
	ld.param.u64 	%rd4, [_Z4GEMMP6__halfS0_PfS1_iii_param_1];
	ld.param.u64 	%rd5, [_Z4GEMMP6__halfS0_PfS1_iii_param_2];
	ld.param.u32 	%r33, [_Z4GEMMP6__halfS0_PfS1_iii_param_5];
	ld.param.u32 	%r34, [_Z4GEMMP6__halfS0_PfS1_iii_param_6];
	mov.u32 	%r1, %ntid.y;
	mov.u32 	%r2, %ntid.x;
	mul.lo.s32 	%r3, %r1, %r2;
	mov.u32 	%r35, %ntid.z;
	mul.lo.s32 	%r4, %r3, %r35;
	setp.lt.s32	%p2, %r4, 96;
	@%p2 bra 	BB0_2;
	bra.uni 	BB0_1;

BB0_2:
	shr.s32 	%r42, %r4, 31;
	shr.u32 	%r43, %r42, 27;
	add.s32 	%r44, %r4, %r43;
	shr.s32 	%r161, %r44, 5;
	mov.u32 	%r162, 32;
	bra.uni 	BB0_3;

BB0_1:
	shr.s32 	%r37, %r4, 31;
	shr.u32 	%r38, %r37, 26;
	add.s32 	%r39, %r4, %r38;
	shr.s32 	%r40, %r39, 6;
	shl.b32 	%r162, %r40, 5;
	mov.u32 	%r161, 2;

BB0_3:
	cvta.to.global.u64 	%rd1, %rd5;
	mov.u32 	%r45, %tid.z;
	mov.u32 	%r46, %tid.y;
	mad.lo.s32 	%r47, %r45, %r1, %r46;
	mov.u32 	%r48, %tid.x;
	mad.lo.s32 	%r9, %r47, %r2, %r48;
	shr.s32 	%r49, %r9, 31;
	shr.u32 	%r50, %r49, 27;
	add.s32 	%r51, %r9, %r50;
	shr.s32 	%r52, %r51, 5;
	rem.s32 	%r10, %r52, %r161;
	div.s32 	%r11, %r52, %r161;
	mov.u32 	%r53, %ctaid.y;
	shl.b32 	%r54, %r53, 6;
	mov.u32 	%r55, %ctaid.x;
	shl.b32 	%r56, %r55, 6;
	mad.lo.s32 	%r12, %r54, %r33, %r56;
	setp.gt.s32	%p3, %r9, 4095;
	@%p3 bra 	BB0_6;

	mov.u32 	%r163, %r9;

BB0_5:
	shr.s32 	%r57, %r163, 31;
	shr.u32 	%r58, %r57, 26;
	add.s32 	%r59, %r163, %r58;
	shr.s32 	%r60, %r59, 6;
	and.b32  	%r61, %r59, -64;
	sub.s32 	%r62, %r163, %r61;
	mad.lo.s32 	%r63, %r60, %r33, %r62;
	add.s32 	%r64, %r12, %r63;
	mul.wide.s32 	%rd7, %r64, 4;
	add.s64 	%rd8, %rd1, %rd7;
	ld.global.f32 	%f65, [%rd8];
	shl.b32 	%r65, %r163, 2;
	mov.u32 	%r66, _ZZ4GEMMP6__halfS0_PfS1_iiiE5csmem;
	add.s32 	%r67, %r66, %r65;
	st.shared.f32 	[%r67], %f65;
	add.s32 	%r163, %r163, %r3;
	setp.lt.s32	%p4, %r163, 4096;
	@%p4 bra 	BB0_5;

BB0_6:
	bar.sync 	0;
	setp.lt.s32	%p5, %r34, 1;
	@%p5 bra 	BB0_20;

	shl.b32 	%r15, %r11, 5;
	shl.b32 	%r16, %r10, 5;
	shl.b32 	%r17, %r161, 5;
	mov.u32 	%r164, 0;
	cvta.to.global.u64 	%rd9, %rd3;
	cvta.to.global.u64 	%rd2, %rd4;

BB0_8:
	mov.u32 	%r153, %ctaid.x;
	shl.b32 	%r152, %r153, 6;
	mov.u32 	%r151, %ctaid.y;
	shl.b32 	%r150, %r151, 6;
	mad.lo.s32 	%r19, %r150, %r34, %r164;
	mad.lo.s32 	%r20, %r164, %r33, %r152;
	setp.gt.s32	%p6, %r9, 2047;
	mov.u32 	%r165, %r9;
	@%p6 bra 	BB0_12;

BB0_9:
	shr.s32 	%r73, %r165, 31;
	shr.u32 	%r74, %r73, 27;
	add.s32 	%r75, %r165, %r74;
	shr.s32 	%r76, %r75, 5;
	and.b32  	%r77, %r75, -32;
	sub.s32 	%r78, %r165, %r77;
	shl.b32 	%r79, %r165, 1;
	mov.u32 	%r80, _ZZ4GEMMP6__halfS0_PfS1_iiiE5asmem;
	add.s32 	%r81, %r80, %r79;
	mad.lo.s32 	%r82, %r76, %r34, %r78;
	add.s32 	%r83, %r19, %r82;
	mul.wide.s32 	%rd10, %r83, 2;
	add.s64 	%rd11, %rd9, %rd10;
	ld.global.u16 	%rs1, [%rd11];
	st.shared.u16 	[%r81], %rs1;
	add.s32 	%r165, %r165, %r3;
	setp.lt.s32	%p7, %r165, 2048;
	@%p7 bra 	BB0_9;

	mov.u32 	%r166, %r9;
	@%p6 bra 	BB0_12;

BB0_11:
	shl.b32 	%r86, %r166, 1;
	mov.u32 	%r87, _ZZ4GEMMP6__halfS0_PfS1_iiiE5bsmem;
	add.s32 	%r88, %r87, %r86;
	shr.s32 	%r89, %r166, 31;
	shr.u32 	%r90, %r89, 26;
	add.s32 	%r91, %r166, %r90;
	shr.s32 	%r92, %r91, 6;
	and.b32  	%r93, %r91, -64;
	sub.s32 	%r94, %r166, %r93;
	mad.lo.s32 	%r95, %r92, %r33, %r94;
	add.s32 	%r96, %r20, %r95;
	mul.wide.s32 	%rd12, %r96, 2;
	add.s64 	%rd13, %rd2, %rd12;
	ld.global.u16 	%rs2, [%rd13];
	st.shared.u16 	[%r88], %rs2;
	add.s32 	%r166, %r166, %r3;
	setp.lt.s32	%p9, %r166, 2048;
	@%p9 bra 	BB0_11;

BB0_12:
	setp.lt.s32	%p1, %r15, 64;
	bar.sync 	0;
	mov.u32 	%r167, %r15;
	@!%p1 bra 	BB0_19;
	bra.uni 	BB0_13;

BB0_13:
	setp.gt.s32	%p10, %r16, 63;
	@%p10 bra 	BB0_18;

	mov.u32 	%r168, %r16;

BB0_15:
	shl.b32 	%r157, %r167, 6;
	mov.u32 	%r156, _ZZ4GEMMP6__halfS0_PfS1_iiiE5asmem;
	add.s32 	%r155, %r156, %r157;
	mul.lo.s32 	%r154, %r167, %r33;
	mov.u32 	%r99, _ZZ4GEMMP6__halfS0_PfS1_iiiE5csmem;
	add.s32 	%r100, %r168, %r154;
	shl.b32 	%r101, %r100, 2;
	add.s32 	%r102, %r101, %r99;
	mov.u32 	%r103, 64;
	wmma.load.c.sync.aligned.row.m16n16k16.shared.f32 	{%f68, %f69, %f70, %f71, %f72, %f73, %f74, %f75}, [%r102], %r103;
	add.s32 	%r104, %r102, 64;
	wmma.load.c.sync.aligned.row.m16n16k16.shared.f32 	{%f76, %f77, %f78, %f79, %f80, %f81, %f82, %f83}, [%r104], %r103;
	add.s32 	%r105, %r102, 4096;
	wmma.load.c.sync.aligned.row.m16n16k16.shared.f32 	{%f84, %f85, %f86, %f87, %f88, %f89, %f90, %f91}, [%r105], %r103;
	add.s32 	%r106, %r102, 4160;
	wmma.load.c.sync.aligned.row.m16n16k16.shared.f32 	{%f92, %f93, %f94, %f95, %f96, %f97, %f98, %f99}, [%r106], %r103;
	mov.u32 	%r107, 32;
	wmma.load.a.sync.aligned.row.m16n16k16.shared.f16 	{%r108, %r109, %r110, %r111, %r112, %r113, %r114, %r115}, [%r155], %r107;
	shl.b32 	%r116, %r168, 1;
	mov.u32 	%r117, _ZZ4GEMMP6__halfS0_PfS1_iiiE5bsmem;
	add.s32 	%r118, %r117, %r116;
	wmma.load.b.sync.aligned.row.m16n16k16.shared.f16 	{%r119, %r120, %r121, %r122, %r123, %r124, %r125, %r126}, [%r118], %r103;
	wmma.mma.sync.aligned.row.row.m16n16k16.f32.f32 {%f155, %f154, %f153, %f152, %f151, %f150, %f149, %f148}, {%r108, %r109, %r110, %r111, %r112, %r113, %r114, %r115}, {%r119, %r120, %r121, %r122, %r123, %r124, %r125, %r126}, {%f68, %f69, %f70, %f71, %f72, %f73, %f74, %f75};
	setp.lt.s32	%p11, %r34, 17;
	@%p11 bra 	BB0_17;

	shl.b32 	%r160, %r167, 6;
	mov.u32 	%r159, _ZZ4GEMMP6__halfS0_PfS1_iiiE5asmem;
	add.s32 	%r158, %r159, %r160;
	add.s32 	%r127, %r158, 32;
	wmma.load.a.sync.aligned.row.m16n16k16.shared.f16 	{%r129, %r130, %r131, %r132, %r133, %r134, %r135, %r136}, [%r127], %r107;
	add.s32 	%r139, %r116, %r117;
	add.s32 	%r140, %r139, 2048;
	wmma.load.b.sync.aligned.row.m16n16k16.shared.f16 	{%r142, %r143, %r144, %r145, %r146, %r147, %r148, %r149}, [%r140], %r103;
	wmma.mma.sync.aligned.row.row.m16n16k16.f32.f32 {%f155, %f154, %f153, %f152, %f151, %f150, %f149, %f148}, {%r129, %r130, %r131, %r132, %r133, %r134, %r135, %r136}, {%r142, %r143, %r144, %r145, %r146, %r147, %r148, %r149}, {%f155, %f154, %f153, %f152, %f151, %f150, %f149, %f148};

BB0_17:
	add.s32 	%r168, %r168, %r17;
	setp.lt.s32	%p12, %r168, 64;
	@%p12 bra 	BB0_15;

BB0_18:
	add.s32 	%r167, %r167, %r162;
	setp.lt.s32	%p13, %r167, 64;
	@%p13 bra 	BB0_13;

BB0_19:
	add.s32 	%r164, %r164, 32;
	setp.lt.s32	%p14, %r164, %r34;
	@%p14 bra 	BB0_8;

BB0_20:
	ld.param.u64 	%rd23, [_Z4GEMMP6__halfS0_PfS1_iii_param_3];
	cvta.to.global.u64 	%rd22, %rd23;
	wmma.store.d.sync.aligned.row.m16n16k16.global.f32 	[%rd22], {%f155, %f154, %f153, %f152, %f151, %f150, %f149, %f148}, %r33;
	wmma.store.d.sync.aligned.row.m16n16k16.global.f32 	[%rd22], {%f100, %f101, %f102, %f103, %f104, %f105, %f106, %f107}, %r33;
	wmma.store.d.sync.aligned.row.m16n16k16.global.f32 	[%rd22], {%f108, %f109, %f110, %f111, %f112, %f113, %f114, %f115}, %r33;
	wmma.store.d.sync.aligned.row.m16n16k16.global.f32 	[%rd22], {%f116, %f117, %f118, %f119, %f120, %f121, %f122, %f123}, %r33;
	ret;
}


